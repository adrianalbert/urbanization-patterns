{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys, os, time\n",
    "import glob\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# these magics ensure that external modules that are modified are also automatically reloaded\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# widgets and interaction\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "\n",
    "from skimage.io import imread, imsave\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import random\n",
    "\n",
    "opt = [\n",
    " (\"dataroot\", \"/home/adalbert/data/world-cities/\"), \n",
    " (\"workers\", 2),\n",
    " (\"batchSize\",64), \n",
    " (\"imageSize\",64),\n",
    " (\"nz\",100),\n",
    " (\"ngf\",64), # nr filters for generator\n",
    " (\"ndf\",64), # nr filters for discriminator\n",
    " (\"niter\",25),\n",
    " (\"lr\",0.0002),\n",
    " (\"beta1\",0.5), \n",
    " (\"cuda\",True),\n",
    " (\"ngpu\",1),\n",
    " (\"netG\",\"\"),\n",
    " (\"netD\",\"\"),\n",
    " (\"outf\",\"/home/adalbert/nbserver/pytorch-workspace/dcgan/\"),\n",
    " (\"manualSeed\",  random.randint(1, 10000)) \n",
    "]\n",
    "opt = namedtuple(\"opt\", dict(opt).keys())(**dict(opt))\n",
    "\n",
    "opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "files = glob.glob(opt.dataroot + \"*/*/*/*.png\")\n",
    "files_df = []\n",
    "for f in files:\n",
    "    s = f.split(\"/\")\n",
    "    fname, cls, res, scale = \\\n",
    "        s[-1], s[-2], int(s[-3].split(\"-\")[0]), int(s[-4].split(\"-\")[0])\n",
    "    _,country,city,_,pop,lat,lon = fname.split(\"_\")\n",
    "    files_df.append((f, cls, res, scale, country, pop))\n",
    "    \n",
    "files_df = pd.DataFrame(files_df, \\\n",
    "                columns=[\"filename\", \"class\", \"res-px\", \"scale-km\", \"country\", \"population\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(files_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sel_df = files_df[(files_df['res-px']==224) & \n",
    "                  (files_df['scale-km']==100)]\n",
    "\n",
    "idx = np.random.choice(range(len(sel_df)), int(len(sel_df)*0.95), replace=False)\n",
    "train_df = sel_df.iloc[idx]\n",
    "test_df  = sel_df.iloc[list(set(range(len(sel_df))) - set(idx))]\n",
    "\n",
    "train_df.to_csv(opt.dataroot + \"/train.csv\")\n",
    "test_df.to_csv(opt.dataroot + \"/test.csv\")\n",
    "\n",
    "len(train_df), len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train - spawn external process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "script_path = \"../models/dcgan-mod.py\"\n",
    "train_file = \"/home/adalbert/data/world-cities/train.csv\"\n",
    "outfolder = opt.outf + \"/100km/\"\n",
    "\n",
    "cmd = \"python {0} --cuda --dataset=csvfile --dataroot={1} --niter={2} --ngpu={3} --outf={4} --imageSize={5}\".format(script_path, train_file, opt.niter, opt.ngpu, outfolder, opt.imageSize)\n",
    "cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "pimg = Image.open(train_df['filename'].iloc[0]).convert(\"L\")\n",
    "img = np.array(pimg)\n",
    "img[abs(img-0.5)<0.01] = 1\n",
    "pimg = Image.fromarray(np.uint8(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d.getband(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot fake and real samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = imread(train_df.sample()['filename'].iloc[0])\n",
    "img = img / float(img.max())\n",
    "img = 1-img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(1-img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files_fake = glob.glob(opt.outf + \"/100km/fake*.png\")\n",
    "files_fake.sort()\n",
    "\n",
    "files_real = glob.glob(opt.outf + \"/100km/real*.png\")\n",
    "\n",
    "files_cptD = glob.glob(opt.outf + \"/100km/netD*.pth\")\n",
    "files_cptD.sort()\n",
    "files_cptG = glob.glob(opt.outf + \"/100km/netG*.pth\")\n",
    "files_cptG.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(imread(files_real[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for f in files_fake:\n",
    "    img = imread(f)\n",
    "    plt.imshow(img)\n",
    "    plt.title(os.path.basename(f))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = imread(opt.outf + \"/100km/training_progress.jpg\")\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering with GAN generator features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files_cptD = {int(os.path.basename(f).split(\".\")[0].split(\"_\")[-1]):f \\\n",
    "              for f in files_cptD}\n",
    "\n",
    "files_cptG = {int(os.path.basename(f).split(\".\")[0].split(\"_\")[-1]):f \\\n",
    "              for f in files_cptG}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ngpu = int(opt.ngpu)\n",
    "nz = int(opt.nz)\n",
    "ngf = int(opt.ngf)\n",
    "ndf = int(opt.ndf)\n",
    "nc = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "class _netD(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(_netD, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, input):\n",
    "        gpu_ids = None\n",
    "        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n",
    "            gpu_ids = range(self.ngpu)\n",
    "        output = nn.parallel.data_parallel(self.main, input, gpu_ids)\n",
    "        return output.view(-1, 1)\n",
    "    \n",
    "netD = _netD(ngpu)\n",
    "netD.apply(weights_init)\n",
    "\n",
    "class _netG(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(_netG, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(     nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d(    ngf,      nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "    def forward(self, input):\n",
    "        gpu_ids = None\n",
    "        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n",
    "            gpu_ids = range(self.ngpu)\n",
    "        return nn.parallel.data_parallel(self.main, input, gpu_ids)\n",
    "\n",
    "netG = _netG(ngpu)\n",
    "netG.apply(weights_init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "netD.load_state_dict(torch.load(files_cptD[max(files_cptD.keys())]))\n",
    "\n",
    "feature_extractor = nn.Sequential(*list(list(netD.children())[0].children())[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys.path.append(\"../pytorch_utils\")\n",
    "from loader_dataframe import ImageDataFrame, grayscale_loader\n",
    "\n",
    "dataset = ImageDataFrame(df=test_df,\n",
    "                         loader=grayscale_loader,\n",
    "                         transform=transforms.Compose([\n",
    "                               transforms.Scale(opt.imageSize),\n",
    "                               transforms.CenterCrop(opt.imageSize),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "\n",
    "assert dataset\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=opt.batchSize,\n",
    "                                     shuffle=False, num_workers=int(opt.workers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "input = torch.FloatTensor(opt.batchSize, nc, opt.imageSize, opt.imageSize)\n",
    "\n",
    "if opt.cuda:\n",
    "    netD.cuda()\n",
    "    input = input.cuda()\n",
    "\n",
    "input = Variable(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "features = []\n",
    "for i, data in enumerate(dataloader):\n",
    "    netD.zero_grad()\n",
    "    real_cpu, lab_batch = data\n",
    "    batch_size = real_cpu.size(0)\n",
    "    input.data.resize_(real_cpu.size()).copy_(real_cpu)\n",
    "    feat_batch = feature_extractor(input)\n",
    "    feat_batch = feat_batch.data.cpu().numpy().reshape((batch_size,-1))\n",
    "    \n",
    "    features.append(feat_batch)\n",
    "    labels.append(lab_batch.numpy())\n",
    "\n",
    "features = np.vstack(features)\n",
    "labels = np.hstack(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "\n",
    "pca = decomposition.PCA(n_components=50)\n",
    "\n",
    "feat_reduced = pca.fit_transform(features)[:,:40]\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.title(\"PCA Components Variance Explained\")\n",
    "plt.xlabel(\"# components\")\n",
    "plt.ylabel(\"% variance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # https://github.com/DmitryUlyanov/Multicore-TSNE\n",
    "\n",
    "# from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "\n",
    "# tsne = TSNE(n_components=20, perplexity=30)\n",
    "# feats_tsne = tsne.fit_transform(features.astype(np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "loss_vec = []\n",
    "k_vec = np.linspace(5, 150, 40)\n",
    "for k in k_vec:\n",
    "    print int(k),\n",
    "    kmeans = KMeans(n_clusters=int(k), random_state=0).fit(feat_reduced)\n",
    "    loss = -kmeans.score(feat_reduced)\n",
    "    loss_vec.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,4))\n",
    "plt.plot(k_vec, np.array(loss_vec)/1e6)\n",
    "plt.title(\"K-Means loss vs # clusters\")\n",
    "plt.xlabel(\"# Clusters\")\n",
    "plt.ylabel(\"loss (/1e6)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=25, random_state=0).fit(feat_reduced)\n",
    "\n",
    "C = kmeans.predict(feat_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(pd.Series(C).value_counts() / float(len(C))).plot(kind=\"barh\", figsize=(4,4))\n",
    "plt.title(\"Cluster Membership Distribution\")\n",
    "plt.xlabel(\"pct membership\")\n",
    "plt.ylabel(\"cluster ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_examples(image_paths, labels, classes=None, \\\n",
    "                  nExamples=10, thumbSize = (64,64), title=\"example\"):\n",
    "    # build example canvass \n",
    "    from skimage.transform import resize\n",
    "    from skimage.io import imread\n",
    "    \n",
    "    clustLabels = np.unique(labels)\n",
    "    nClusters = clustLabels.size\n",
    "    canvas = np.zeros((thumbSize[0]*nClusters, nExamples*thumbSize[1]))\n",
    "    for i,c in enumerate(clustLabels):\n",
    "        cur_class_samples = np.where(labels==c)[0]\n",
    "        idx = np.random.choice(cur_class_samples, replace=False, size=min([nExamples, len(cur_class_samples)]))\n",
    "        for j in range(len(idx)):\n",
    "            img = imread(image_paths[idx[j]])\n",
    "            img = img / float(img.max())\n",
    "            img[abs(img-0.5)<0.01] = 0 # hack to remove no-data patches\n",
    "            img = 1-img\n",
    "            img = resize(img, thumbSize)\n",
    "            canvas[i*thumbSize[0]:(i+1)*thumbSize[0], j*thumbSize[1]:(j+1)*thumbSize[1]] = img\n",
    "    \n",
    "    # plot examples of each class\n",
    "    fig,ax = plt.subplots(1, figsize=(12,10))\n",
    "    plt.tight_layout()\n",
    "    print canvas.shape\n",
    "    ax.imshow(canvas.swapaxes(0,1))#, aspect='auto')\n",
    "    ax.set_title(title, fontsize=18)\n",
    "    ax.set_ylabel(\"-- examples --\", fontsize=16)\n",
    "    ax.set_xlabel(\"-- land classes --\", fontsize=16)\n",
    "    # Turn off tick labels\n",
    "    if classes is None: classes = clustLabels\n",
    "    ax.set_xticks([thumbSize[0]*(0.5 + x) for x in range(nClusters)])\n",
    "    ax.set_xticklabels(classes, fontsize=16, rotation=90)\n",
    "    ax.set_yticklabels([])\n",
    "    #plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_examples(test_df['filename'].values, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
